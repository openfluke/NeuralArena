package main

import (
	"fmt"
	"math"
	"math/rand"
	"os"
	"strings"
	"time"

	"paragon" // Replace with actual import path, e.g., "github.com/username/paragon"
)

// Pair defines a word-emoticon pair
type Pair struct {
	Word     string
	Emoticon string
}

// Training data from your provided list
var pairs = []Pair{
	{"acid", "âŠ‚(â—‰â€¿â—‰)ã¤"},
	{"afraid", "(ã†† _ ã††)"},
	{"alpha", "Î±"},
	{"angel", "â˜œ(âŒ’â–½âŒ’)â˜"},
	{"angry", "â€¢`_Â´â€¢"},
	{"arrowhead", "â¤œ(â±º Ê–Ì¯â±º)â¤"},
	{"apple", "ï£¿"},
	{"ass", "(â€¿|â€¿)"},
	{"butt", "(â€¿|â€¿)"},
	{"awkward", "â€¢Í¡Ë˜ã‡â€¢Í¡Ë˜"},
	{"bat", "/|\\ ^._.^ /|\\"},
	{"bear", "Ê•Â·Í¡á´¥Â·Ê”"},
	{"koala", "Ê•Â·Í¡á´¥Â·Ê”"},
	{"bearflip", "Ê•ãƒâ€¢á´¥â€¢Ê”ãƒ ï¸µ â”»â”â”»"},
	{"bearhug", "Ê•ã£â€¢á´¥â€¢Ê”ã£"},
	{"because", "âˆµ"},
	{"since", "âˆµ"},
	{"beta", "Î²"},
	{"bigheart", "â¤"},
	{"bitcoin", "â‚¿"},
	{"blackeye", "0__#"},
	{"blubby", "( 0 _ 0 )"},
	{"blush", "(Ëµ Í¡Â° ÍœÊ– Í¡Â°Ëµ)"},
	{"bond", "â”Œ( ÍÂ° ÍœÊ–Í¡Â°)=Îµ/ÌµÍ‡Ì¿Ì¿/â€™Ì¿â€™Ì¿ Ì¿"},
	{"007", "â”Œ( ÍÂ° ÍœÊ–Í¡Â°)=Îµ/ÌµÍ‡Ì¿Ì¿/â€™Ì¿â€™Ì¿ Ì¿"},
	{"boobs", "( . Y . )"},
	{"bored", "(-_-)"},
	{"bribe", "( â€¢Í¡Ë˜ _â€¢Í¡Ë˜)ãƒÃ°"},
	{"bubbles", "( Ë˜ Â³Ë˜)ãƒÂ°ï¾ŸÂºâï½¡"},
	{"butterfly", "Æ¸ÓœÆ·"},
	{"cat", "(= Ğ¤ã‚§Ğ¤=)"},
	{"catlenny", "( Í¡Â° á´¥ Í¡Â°)"},
	{"check", "âœ”"},
	{"cheer", "â€»\\(^o^)/â€»"},
	{"chubby", "â•­(Ê˜Ì†~â—à±ªâ—Ÿ~Ê˜Ì†)â•®"},
	{"claro", "(Í¡ Â° ÍœÊ– Í¡ Â°)"},
	{"clique", "ãƒ½à¼¼ àºˆÙ„Íœàºˆà¼¼ â–€Ì¿Ì¿Ä¹Ì¯Ì¿Ì¿â–€Ì¿ Ì¿à¼½ÆŸÍ†Ù„ÍœÆŸÍ† à¼½ï¾‰"},
	{"gang", "ãƒ½à¼¼ àºˆÙ„Íœàºˆà¼¼ â–€Ì¿Ì¿Ä¹Ì¯Ì¿Ì¿â–€Ì¿ Ì¿à¼½ÆŸÍ†Ù„ÍœÆŸÍ† à¼½ï¾‰"},
	{"squad", "ãƒ½à¼¼ àºˆÙ„Íœàºˆà¼¼ â–€Ì¿Ì¿Ä¹Ì¯Ì¿Ì¿â–€Ì¿ Ì¿à¼½ÆŸÍ†Ù„ÍœÆŸÍ† à¼½ï¾‰"},
	{"cloud", "â˜"},
	{"club", "â™£"},
	{"coffee", "c[_]"},
	{"cuppa", "c[_]"},
	{"cmd", "âŒ˜"},
	{"command", "âŒ˜"},
	{"cool", "(â€¢_â€¢) ( â€¢_â€¢)>âŒâ– -â–  (âŒâ– _â– )"},
	{"csi", "(â€¢_â€¢) ( â€¢_â€¢)>âŒâ– -â–  (âŒâ– _â– )"},
	{"copy", "Â©"},
	{"c", "Â©"},
	{"creep", "Ô…(â‰–â€¿â‰–Ô…)"},
	{"crim3s", "( âœœï¸µâœœ )"},
	{"cross", "â€ "},
	{"cry", "(â•¥ï¹â•¥)"},
	{"crywave", "( â•¥ï¹â•¥) ãƒã‚·"},
	{"cute", "(ï½¡â—•â€¿â€¿â—•ï½¡)"},
	{"d1", "âš€"},
	{"d2", "âš"},
	{"d3", "âš‚"},
	{"d4", "âšƒ"},
	{"d5", "âš„"},
	{"d6", "âš…"},
	{"dab", "ãƒ½( â€¢_)á•—"},
	{"damnyou", "(á•— Í Â° à¨Š Í Â° )á•—"},
	{"dance", "á••(âŒâ– _â– )á•— â™ªâ™¬"},
	{"dead", "xâ¸‘x"},
	{"dealwithit", "(âŒâ– _â– )"},
	{"dwi", "(âŒâ– _â– )"},
	{"delta", "Î”"},
	{"depressed", "(ï¸¶ï¸¹ï¸¶)"},
	{"derp", "â˜‰ â€¿ âš†"},
	{"diamond", "â™¦"},
	{"dj", "d[-_-]b"},
	{"dog", "(â—•á´¥â—•Ê‹)"},
	{"dollar", "$"},
	{"dollarbill", "[Ì²Ì…$Ì²Ì…(Ì²Ì…Î¹Î¿Ì²Ì…Ì…)Ì²Ì…$Ì²Ì…]"},
	{"$", "[Ì²Ì…$Ì²Ì…(Ì²Ì…Î¹Î¿Ì²Ì…Ì…)Ì²Ì…$Ì²Ì…]"},
	{"dong", "(Ì¿â–€Ì¿â€‰Ì¿Ä¹Ì¯Ì¿Ì¿â–€Ì¿ Ì¿)Ì„"},
	{"donger", "ãƒ½à¼¼àºˆÙ„Íœàºˆà¼½ï¾‰"},
	{"dontcare", "(- Ê–Ì¯-)"},
	{"idc", "(- Ê–Ì¯-)"},
	{"donotwant", "ãƒ½(ï½€Ğ”Â´)ï¾‰"},
	{"dontwant", "ãƒ½(ï½€Ğ”Â´)ï¾‰"},
	{"dope", "<(^_^)>"},
	{"<<", "Â«"},
	{">>", "Â»"},
	{"doubleflat", "ğ„«"},
	{"doublesharp", "ğ„ª"},
	{"doubletableflip", "â”»â”â”» ï¸µãƒ½(`Ğ”Â´)ï¾‰ï¸µ â”»â”â”»"},
	{"down", "â†“"},
	{"duckface", "(ãƒ»3ãƒ»)"},
	{"duel", "á••(â•­à²°â•­ ÍŸÊ–â•®â€¢Ì)âŠƒÂ¤=(â€”â€”â€”â€”-"},
	{"duh", "(â‰§ï¸¿â‰¦)"},
	{"dunno", "Â¯\\(Â°_o)/Â¯"},
	{"ebola", "á´‡Ê™á´ÊŸá´€"},
	{"eeriemob", "(-(-_-(-_(-_(-_-)_-)-_-)_-)_-)-)"},
	{"ellipsis", "â€¦"},
	{"...", "â€¦"},
	{"emdash", "â€“"},
	{"--", "â€“"},
	{"emptystar", "â˜†"},
	{"emptytriangle", "â–³"},
	{"t2", "â–³"},
	{"endure", "(Ò‚â—¡_â—¡) á•¤"},
	{"envelope", "âœ‰ï¸"},
	{"letter", "âœ‰ï¸"},
	{"epsilon", "É›"},
	{"euro", "â‚¬"},
	{"evil", "Ïˆ(ï½€âˆ‡Â´)Ïˆ"},
	{"evillenny", "(Í â‰– ÍœÊ–Í â‰–)"},
	{"excited", "(ï¾‰â—•ãƒ®â—•)ï¾‰*:ãƒ»ï¾Ÿâœ§"},
	{"execution", "(âŒâ– _â– )ï¸»â•¦â•¤â”€ (â•¥ï¹â•¥)"},
	{"facebook", "(â•¯Â°â–¡Â°)â•¯ï¸µ ÊooqÇÉ”ÉÉŸ"},
	{"facepalm", "(ï¼â€¸áƒš)"},
	{"fancytext", "Ğ²Ñ”Ï‰Î±ÑÑ”, Î¹ Î±Ğ¼ Æ’Î±Î·Â¢Ñƒ!"},
	{"fart", "(Ë†âº«Ë†à¹‘)<3"},
	{"fight", "(à¸‡ â€¢Ì€_â€¢Ì)à¸‡"},
	{"finn", "| (â€¢ â—¡â€¢)|"},
	{"fish", "<\"(((<3"},
	{"5", "åŒ"},
	{"five", "åŒ"},
	{"5/8", "â…"},
	{"flat", "â™­"},
	{"bemolle", "â™­"},
	{"flexing", "á•™(`â–½Â´)á•—"},
	{"fliptext", "Ç×ŸqÉÊ‡ É ÇÊÄ±×Ÿ ÇÉ¯ dÄ±×ŸÉŸ"},
	{"fliptexttable", "(ãƒ ã‚œĞ”ã‚œ)ãƒ ï¸µ Ç×ŸqÉÊ‡ É ÇÊÄ±×Ÿ Ê‡xÇÊ‡ dÄ±×ŸÉŸ"},
	{"flower", "(âœ¿â— â€¿â— )"},
	{"flor", "(âœ¿â— â€¿â— )"},
	{"f", "âœ¿"},
	{"fly", "â”€=â‰¡Î£((( ã¤â—•Ù„Íœâ—•)ã¤"},
	{"friendflip", "(â•¯Â°â–¡Â°)â•¯ï¸µ â”»â”â”» ï¸µ â•¯(Â°â–¡Â° â•¯)"},
	{"frown", "(áƒ¦Ë˜âŒ£Ë˜áƒ¦)"},
	{"fuckoff", "à­§à¼¼à² ç›Šà² â•­âˆ©â•®à¼½"},
	{"gtfo", "à­§à¼¼à² ç›Šà² â•­âˆ©â•®à¼½"},
	{"fuckyou", "â”ŒĞŸâ”(à² _à² )"},
	{"fu", "â”ŒĞŸâ”(à² _à² )"},
	{"gentleman", "à² _à²°à³ƒ"},
	{"sir", "à² _à²°à³ƒ"},
	{"monocle", "à² _à²°à³ƒ"},
	{"ghast", "= _ ="},
	{"ghost", "à¼¼ ã¤ â•¹ â•¹ à¼½ã¤"},
	{"gift", "(Â´ãƒ»Ï‰ãƒ»)ã£ç”±"},
	{"present", "(Â´ãƒ»Ï‰ãƒ»)ã£ç”±"},
	{"gimme", "à¼¼ ã¤ â—•_â—• à¼½ã¤"},
	{"givemeyourmoney", "(â€¢-â€¢)âŒ"},
	{"glitter", "(*ãƒ»â€¿ãƒ»)ãƒâŒ’*:ï½¥ï¾Ÿâœ§"},
	{"glasses", "(âŒ Í¡â–  ÍœÊ– Í¡â– )"},
	{"glassesoff", "( Í¡Â° ÍœÊ– Í¡Â°)ï¾‰âŒâ– -â– "},
	{"glitterderp", "(ï¾‰â˜‰ãƒ®âš†)ï¾‰ âŒ’*:ï½¥ï¾Ÿâœ§"},
	{"gloomy", "(_ã‚œ_ã‚œ_)"},
	{"goatse", "(Ğ·à¹Îµ)"},
	{"gotit", "(â˜ï¾Ÿâˆ€ï¾Ÿ)â˜"},
	{"greet", "( Â´â—” Ï‰â—”`) ãƒã‚·"},
	{"greetings", "( Â´â—” Ï‰â—”`) ãƒã‚·"},
	{"gun", "ï¸»â•¦â•¤â”€"},
	{"mg", "ï¸»â•¦â•¤â”€"},
	{"hadouken", "à¼¼ã¤à² ç›Šà² à¼½ã¤ â”€=â‰¡Î£O))"},
	{"hammerandsickle", "â˜­"},
	{"hs", "â˜­"},
	{"handleft", "â˜œ"},
	{"hl", "â˜œ"},
	{"handright", "â˜"},
	{"hr", "â˜"},
	{"haha", "Ù©(^â€¿^)Û¶"},
	{"happy", "Ù©( à¹‘â•¹ ê‡´â•¹)Û¶"},
	{"happygarry", "á••( á› )á•—"},
	{"h", "â™¥"},
	{"heart", "â™¥"},
	{"hello", "(Ê˜â€¿Ê˜)â•¯"},
	{"ohai", "(Ê˜â€¿Ê˜)â•¯"},
	{"bye", "(Ê˜â€¿Ê˜)â•¯"},
	{"help", "\\(Â°Î©Â°)/"},
	{"highfive", "._.)/\\(._."},
	{"hitting", "( ï½€çš¿Â´)ï½¡ï¾/"},
	{"hug", "(ã¥ï½¡â—•â€¿â€¿â—•ï½¡)ã¥"},
	{"hugs", "(ã¥ï½¡â—•â€¿â€¿â—•ï½¡)ã¥"},
	{"iknowright", "â”ï½œï½¥à¸´Ï‰ï½¥à¸´#ï½œâ”Œ"},
	{"ikr", "â”ï½œï½¥à¸´Ï‰ï½¥à¸´#ï½œâ”Œ"},
	{"illuminati", "à­§(â–²á´—â–²)ãƒ"},
	{"infinity", "âˆ"},
	{"inf", "âˆ"},
	{"inlove", "(ã£Â´Ï‰`c)â™¡"},
	{"int", "âˆ«"},
	{"internet", "à¬˜(à©­*ËŠáµ•Ë‹)à©­*â€ŠÌ€Ë‹ ÉªÉ´á´›á´‡Ê€É´á´‡á´›"},
	{"interrobang", "â€½"},
	{"jake", "(âá´¥âÊ‹)"},
	{"kappa", "(Â¬,â€¿,Â¬)"},
	{"kawaii", "â‰§â—¡â‰¦"},
	{"keen", "â”¬â”´â”¬â”´â”¤ÆŸÍ†Ù„ÍœÆŸÍ† à¼½ï¾‰"},
	{"kiahh", "~\\(â‰§â–½â‰¦)/~"},
	{"kiss", "(ã¥ ï¿£ Â³ï¿£)ã¥"},
	{"kyubey", "ï¼äººâ—• â€¿â€¿ â—•äººï¼¼"},
	{"lambda", "Î»"},
	{"lazy", "_(:3ã€âˆ )_"},
	{"left", "â†"},
	{"<-", "â†"},
	{"lenny", "( Í¡Â° ÍœÊ– Í¡Â°)"},
	{"lennybill", "[Ì²Ì…$Ì²Ì…(Ì²Ì… Í¡Â° ÍœÊ– Í¡Â°Ì²Ì…)Ì²Ì…$Ì²Ì…]"},
	{"lennyfight", "(à¸‡ Í Â° ÍŸÊ– Í¡Â°)à¸‡"},
	{"lennyflip", "(ãƒ Í¡Â° ÍœÊ– Í¡Â°ãƒ) ï¸µ ( Íœã€‚ Í¡Ê– Íœã€‚)"},
	{"lennygang", "( Í¡Â°( Í¡Â° ÍœÊ–( Í¡Â° ÍœÊ– Í¡Â°)Ê– Í¡Â°) Í¡Â°)"},
	{"lennyshrug", "Â¯\\_( Í¡Â° ÍœÊ– Í¡Â°)_/Â¯"},
	{"lennysir", "( à²  ÍœÊ– à²°à³ƒ)"},
	{"lennystalker", "â”¬â”´â”¬â”´â”¤( Í¡Â° ÍœÊ–â”œâ”¬â”´â”¬â”´"},
	{"lennystrong", "á•¦( Í¡Â° ÍœÊ– Í¡Â°)á•¤"},
	{"lennywizard", "â•°( Í¡Â° ÍœÊ– Í¡Â° )ã¤â”€â”€â˜†*:ãƒ»ï¾Ÿ"},
	{"loading", "â–ˆâ–ˆâ–ˆâ–’â–’â–’â–’â–’â–’â–’"},
	{"lol", "L(Â° O Â°L)"},
	{"look", "(à²¡_à²¡)â˜"},
	{"loud", "á•¦(â©¾ï¹â©½)á•¥"},
	{"noise", "á•¦(â©¾ï¹â©½)á•¥"},
	{"love", "â™¥â€¿â™¥"},
	{"lovebear", "Ê•â™¥á´¥â™¥Ê”"},
	{"lumpy", "ê’° ê’¡âŒ“ê’¡ê’±"},
	{"luv", "-`áƒ¦Â´-"},
	{"magic", "ãƒ½(ï½€Ğ”Â´)âŠƒâ”â˜†ï¾Ÿ. * ï½¥ ï½¡ï¾Ÿ,"},
	{"magicflip", "(/Â¯â—¡ â€¿ â—¡)/Â¯ ~ â”»â”â”»"},
	{"meep", "\\(Â°^Â°)/"},
	{"meh", "à² _à² "},
	{"metal", "\\m/,(> . <)_\\m/"},
	{"rock", "\\m/,(> . <)_\\m/"},
	{"mistyeyes", "à²¡_à²¡"},
	{"monster", "à¼¼ à¼àº¶ à·´ à¼àº¶à¼½"},
	{"natural", "â™®"},
	{"needle", "â”Œ(â—‰ ÍœÊ–â—‰)ã¤â”£â–‡â–‡â–‡â•â”€â”€"},
	{"inject", "â”Œ(â—‰ ÍœÊ–â—‰)ã¤â”£â–‡â–‡â–‡â•â”€â”€"},
	{"nerd", "(âŒâŠ™_âŠ™)"},
	{"nice", "( Í¡Â° Íœ Â°)"},
	{"no", "â†’_â†"},
	{"noclue", "ï¼äººâ—• __ â—•äººï¼¼"},
	{"nom", "(ã£Ë†Ú¡Ë†Ï‚)"},
	{"yummy", "(ã£Ë†Ú¡Ë†Ï‚)"},
	{"delicious", "(ã£Ë†Ú¡Ë†Ï‚)"},
	{"note", "â™«"},
	{"sing", "â™«"},
	{"nuclear", "â˜¢"},
	{"radioactive", "â˜¢"},
	{"nukular", "â˜¢"},
	{"nyan", "~=[,,_,,]:3"},
	{"nyeh", "@^@"},
	{"ohshit", "( Âºï¹ƒÂº )"},
	{"omega", "Î©"},
	{"omg", "â—•_â—•"},
	{"1/8", "â…›"},
	{"1/4", "Â¼"},
	{"1/2", "Â½"},
	{"1/3", "â…“"},
	{"opt", "âŒ¥"},
	{"option", "âŒ¥"},
	{"orly", "(ëˆˆ_ëˆˆ)"},
	{"ohyou", "(â—à°¥à±ªà°¥)á´–"},
	{"ou", "(â—à°¥à±ªà°¥)á´–"},
	{"peace", "âœŒ(-â€¿-)âœŒ"},
	{"victory", "âœŒ(-â€¿-)âœŒ"},
	{"pear", "(__>-"},
	{"pi", "Ï€"},
	{"pingpong", "( â€¢_â€¢)O*Â¯`Â·.Â¸.Â·Â´Â¯`Â°Q(â€¢_â€¢ )"},
	{"plain", "._."},
	{"pleased", "(Ë¶â€¾á·„ â»Ì« â€¾á·…Ëµ)"},
	{"point", "(â˜ï¾Ÿãƒ®ï¾Ÿ)â˜"},
	{"pooh", "Ê• â€¢ÌØˆâ€¢Ì€)"},
	{"porcupine", "(â€¢á´¥â€¢ )Ì`Ì'Ì`Ì'Ìâ»"},
	{"pound", "Â£"},
	{"praise", "(â˜ Õà¨Š Õ)â˜"},
	{"punch", "O=('-'Q)"},
	{"rage", "t(à² ç›Šà² t)"},
	{"mad", "t(à² ç›Šà² t)"},
	{"rageflip", "(ãƒà² ç›Šà² )ãƒå½¡â”»â”â”»"},
	{"rainbowcat", "(=^ï½¥ï½ªï½¥^=))ï¾‰å½¡â˜†"},
	{"really", "Ã²_Ã´"},
	{"r", "Â®"},
	{"right", "â†’"},
	{"->", "â†’"},
	{"riot", "à­§à¼¼à² ç›Šà² à¼½à­¨"},
	{"rolldice", "âšƒ"},
	{"rolleyes", "(â—”_â—”)"},
	{"rose", "âœ¿Ú¿Ú°Û£â€”"},
	{"run", "(â•¯Â°â–¡Â°)â•¯"},
	{"sad", "Îµ(Â´ï­ï¸µï­`)Ğ·"},
	{"saddonger", "ãƒ½à¼¼àºˆÊ–Ì¯àºˆà¼½ï¾‰"},
	{"sadlenny", "( Í¡Â° Ê–Ì¯ Í¡Â°)"},
	{"7/8", "â…"},
	{"sharp", "â™¯"},
	{"diesis", "â™¯"},
	{"shout", "â•š(â€¢âŒ‚â€¢)â•"},
	{"shrug", "Â¯\\_(ãƒ„)_/Â¯"},
	{"shy", "=^_^="},
	{"sigma", "Î£"},
	{"sum", "Î£"},
	{"skull", "â˜ "},
	{"smile", "ãƒ„"},
	{"smiley", "â˜ºï¸"},
	{"smirk", "Â¬â€¿Â¬"},
	{"snowman", "â˜ƒ"},
	{"sob", "(;Â´à¼àº¶Ğ”à¼àº¶`)"},
	{"soviettableflip", "ãƒâ”¬â”€â”¬ãƒ ï¸µ ( \\oÂ°o)\\"},
	{"spade", "â™ "},
	{"sqrt", "âˆš"},
	{"squid", "<ã‚³:å½¡"},
	{"star", "â˜…"},
	{"strong", "á•™(â‡€â€¸â†¼â€¶)á•—"},
	{"suicide", "Îµ/ÌµÍ‡Ì¿Ì¿/â€™Ì¿â€™Ì¿ Ì¿(â—¡ï¸µâ—¡)"},
	{"sum", "âˆ‘"},
	{"sun", "â˜€"},
	{"surprised", "(à¹‘â€¢Ì ãƒ® â€¢Ì€à¹‘)"},
	{"surrender", "\\_(-_-)_/"},
	{"stalker", "â”¬â”´â”¬â”´â”¤(ï½¥_â”œâ”¬â”´â”¬â”´"},
	{"swag", "(Ì¿â–€Ì¿â€¿â€‰Ì¿â–€Ì¿ Ì¿)"},
	{"sword", "o()xxxx[{::::::::::::::::::>"},
	{"tableflip", "(ãƒ ã‚œĞ”ã‚œ)ãƒ ï¸µ â”»â”â”»"},
	{"tau", "Ï„"},
	{"tears", "(à²¥ï¹à²¥)"},
	{"terrorist", "à­§à¼¼à² ç›Šà² à¼½ï¸»â•¦â•¤â”€"},
	{"thanks", "\\(^-^)/"},
	{"thankyou", "\\(^-^)/"},
	{"ty", "\\(^-^)/"},
	{"therefore", "â¸«"},
	{"so", "â¸«"},
	{"this", "( Í¡Â° ÍœÊ– Í¡Â°)_/Â¯"},
	{"3/8", "â…œ"},
	{"tiefighter", "|=-(Â¤)-=|"},
	{"tired", "(=____=)"},
	{"toldyouso", "â˜œ(ê’¡âŒ“ê’¡)"},
	{"toldyou", "â˜œ(ê’¡âŒ“ê’¡)"},
	{"toogood", "á•¦(Ã²á´¥Ã³)á•¥"},
	{"tm", "â„¢"},
	{"triangle", "â–²"},
	{"t", "â–²"},
	{"2/3", "â…”"},
	{"unflip", "â”¬â”€â”€â”¬ ãƒ(Ã²_Ã³ãƒ)"},
	{"up", "â†‘"},
	{"victory", "(à¹‘â€¢Ì€ã…‚â€¢Ì)à¸‡âœ§"},
	{"wat", "(Ã’Ğ”Ã“×±)"},
	{"wave", "( * ^ *) ãƒã‚·"},
	{"whaa", "Ã–"},
	{"whistle", "(ã£^Ğ·^)â™ªâ™¬"},
	{"whoa", "(Â°oâ€¢)"},
	{"why", "áƒš(`â—‰â—à±ªâ—Ÿâ—‰â€µáƒš)"},
	{"witchtext", "WHÎ£Ğ˜ $HÎ›LL WÎ£ â€ HĞ¯Î£Î£ MÎ£Î£â€  Î›GÎ›|Ğ˜?"},
	{"woo", "ï¼¼(ï¼¾Oï¼¾)ï¼"},
	{"wtf", "(âŠ™ï¼¿âŠ™')"},
	{"wut", "âŠ™Ï‰âŠ™"},
	{"yay", "\\( ï¾Ÿãƒ®ï¾Ÿ)/"},
	{"yeah", "(â€¢Ì€á´—â€¢Ì)Ùˆ Ì‘Ì‘"},
	{"yes", "(â€¢Ì€á´—â€¢Ì)Ùˆ Ì‘Ì‘"},
	{"yen", "Â¥"},
	{"yinyang", "â˜¯"},
	{"yy", "â˜¯"},
	{"yolo", "Yáµ’áµ˜ Oá¶°Ë¡Ê¸ Lá¶¤áµ›áµ‰ Oá¶°á¶œáµ‰"},
	{"youkids", "áƒšà¼¼>â•­ ÍŸÊ–â•®<à¼½áƒš"},
	{"ukids", "áƒšà¼¼>â•­ ÍŸÊ–â•®<à¼½áƒš"},
	{"yuno", "(å±®ï¾ŸĞ”ï¾Ÿ)å±® Y U NO"},
	{"zen", "âŠ¹â•°(âŒ£ÊŸâŒ£)â•¯âŠ¹"},
	{"meditation", "âŠ¹â•°(âŒ£ÊŸâŒ£)â•¯âŠ¹"},
	{"omm", "âŠ¹â•°(âŒ£ÊŸâŒ£)â•¯âŠ¹"},
	{"zoidberg", "(V) (Â°,,,,Â°) (V)"},
	{"zombie", "[Â¬Âº-Â°]Â¬"},
}

// -------------------------------------------------------
// 1) Local helper "Char-level" Encode/Decode
// -------------------------------------------------------
func encodeCharLevel(tok *paragon.CustomTokenizer, text string) []int {
	ids := make([]int, 0, len(text))
	padID := tok.Vocab["[PAD]"]
	for _, char := range text {
		c := string(char)
		if id, ok := tok.Vocab[c]; ok {
			ids = append(ids, id)
		} else {
			ids = append(ids, padID)
		}
	}
	return ids
}

func decodeCharLevel(tok *paragon.CustomTokenizer, ids []int) string {
	var sb strings.Builder
	for _, id := range ids {
		if str, ok := tok.ReverseVocab[id]; ok {
			// Skip if it's a special token
			if !tok.SpecialTokens[id] {
				sb.WriteString(str)
			}
		}
	}
	return sb.String()
}

// -------------------------------------------------------
// 2) Partial masking AFTER [SEP] only
// -------------------------------------------------------
func betterAddNoiseWithSep(d *paragon.DiffusionModel, x0 []int, t int, sepPos int) []int {
	noisy := make([]int, len(x0))
	copy(noisy, x0)

	padID := d.Tokenizer.Vocab["[PAD]"]
	maskID := d.Tokenizer.Vocab["[MASK]"]
	fraction := d.MaskFraction[t]
	if fraction <= 0 {
		return noisy
	}

	// Only consider tokens after [SEP], ignoring pads
	var idxes []int
	for i := sepPos + 1; i < len(x0); i++ {
		if x0[i] != padID {
			idxes = append(idxes, i)
		}
	}
	rand.Shuffle(len(idxes), func(i, j int) { idxes[i], idxes[j] = idxes[j], idxes[i] })

	k := int(math.Round(float64(len(idxes)) * fraction))
	for i := 0; i < k && i < len(idxes); i++ {
		noisy[idxes[i]] = maskID
	}
	return noisy
}

// -------------------------------------------------------
//  3. Batched training: partial masking after [SEP], single backward per batch,
//     measure accuracy, generate examples each epoch. Uses BackwardExternal.
//
// -------------------------------------------------------
func trainBetterDiffusionWithSepBatch(d *paragon.DiffusionModel, samples [][]int, sepPositions []int) {
	data := make([][]int, len(samples))
	copy(data, samples)

	batchSize := 4 // Adjust as desired
	//baseLR := d.Config.LearningRate

	for epoch := 0; epoch < d.Config.Epochs; epoch++ {
		// Simple linear LR decay
		progress := float64(epoch) / float64(d.Config.Epochs)
		lr := d.Config.LearningRate * (math.Cos(progress*math.Pi) + 1) / 2

		// Shuffle data
		rand.Shuffle(len(data), func(i, j int) {
			data[i], data[j] = data[j], data[i]
			sepPositions[i], sepPositions[j] = sepPositions[j], sepPositions[i]
		})

		totalLoss := 0.0
		maskedCorrect := 0
		maskedCount := 0

		// Batch loop
		for i := 0; i < len(data); i += batchSize {
			end := i + batchSize
			if end > len(data) {
				end = len(data)
			}
			batch := data[i:end]
			batchSep := sepPositions[i:end]

			// We'll accumulate error terms for the entire batch, then call BackwardExternal once
			accumError := make([]float64, d.Config.MaxLength*d.Tokenizer.VocabSize)

			localLoss := 0.0
			for idx, x0 := range batch {
				sepPos := batchSep[idx]
				t := rand.Intn(d.Config.NumTimesteps)
				xt := betterAddNoiseWithSep(d, x0, t, sepPos)

				// Build one-hot
				batchInput := make([][]float64, d.Config.MaxLength)
				for k, tok := range xt {
					row := make([]float64, d.Tokenizer.VocabSize)
					if tok >= 0 && tok < d.Tokenizer.VocabSize {
						row[tok] = 1.0
					}
					batchInput[k] = row
				}

				output2D := d.Network.ForwardTransformer(batchInput)
				preds := output2D[0] // shape = [MaxLength * VocabSize]

				maskID := d.Tokenizer.Vocab["[MASK]"]
				for pos, tok := range xt {
					// Only compute loss & accuracy for positions after [SEP] that are masked
					if pos <= sepPos {
						continue
					}
					if tok == maskID {
						start := pos * d.Tokenizer.VocabSize
						endPos := start + d.Tokenizer.VocabSize
						probs := paragon.Softmax(preds[start:endPos])
						target := x0[pos]

						// Cross-entropy
						localLoss -= math.Log(math.Max(probs[target], 1e-10))

						// For accuracy, pick argmax
						best := 0
						bestProb := probs[0]
						for m := 1; m < len(probs); m++ {
							if probs[m] > bestProb {
								bestProb = probs[m]
								best = m
							}
						}
						if best == target {
							maskedCorrect++
						}
						maskedCount++

						// Accumulate error terms
						for m := 0; m < d.Tokenizer.VocabSize; m++ {
							delta := probs[m]
							if m == target {
								delta -= 1
							}
							// gradient clip
							if delta > 5.0 {
								delta = 5.0
							} else if delta < -5.0 {
								delta = -5.0
							}
							accumError[start+m] += delta
						}
					}
				}
			}

			// Average loss over the batch
			localLoss /= float64(len(batch))
			totalLoss += localLoss

			// Now do one backward pass for this batch
			shaped := make([][]float64, d.Config.MaxLength)
			for k := 0; k < d.Config.MaxLength; k++ {
				start := k * d.Tokenizer.VocabSize
				shaped[k] = accumError[start : start+d.Tokenizer.VocabSize]
			}
			d.Network.BackwardExternal(shaped, lr)
		}

		epochLoss := totalLoss / float64(len(data)/batchSize)
		accuracy := 0.0
		if maskedCount > 0 {
			accuracy = float64(maskedCorrect) / float64(maskedCount)
		}

		// Print progress
		fmt.Printf("Epoch %d | LR: %.5f | Loss: %.4f | Masked Acc: %.2f%%\n",
			epoch, lr, epochLoss, accuracy*100.0)

		// Generate sample emoticons each epoch
		if epoch%1 == 0 { // or pick a different interval
			words := []string{"happy", "sad"}
			fmt.Println("Sample generations:")
			for _, w := range words {
				g := generateEmoticon(d, w)
				fmt.Printf("   %s => %s\n", w, g)
			}
			fmt.Println()
		}

		if err := d.Network.SaveToGob("emoticon_model.gob"); err != nil {
			panic(fmt.Errorf("failed to save model to gob: %v", err))
		}

		// Early stop if accuracy >= 95%
		if accuracy >= 0.95 {
			fmt.Println("Early stopping: Reached 95% masked accuracy!")
			break
		}
	}
}

// -------------------------------------------------------
// 4) Single-pass reverse diffusion generator
// -------------------------------------------------------
func generateEmoticon(d *paragon.DiffusionModel, inputWord string) string {
	sepID := d.Tokenizer.Vocab["[SEP]"]
	maskID := d.Tokenizer.Vocab["[MASK]"]
	padID := d.Tokenizer.Vocab["[PAD]"]

	wordIDs := encodeCharLevel(d.Tokenizer, inputWord)
	seq := append(wordIDs, sepID)
	sepPos := len(wordIDs)

	// Fill up to MaxLength with [MASK]
	for len(seq) < d.Config.MaxLength {
		seq = append(seq, maskID)
	}

	// Reverse diffusion
	for t := d.Config.NumTimesteps - 1; t >= 0; t-- {
		// build one-hot
		batchInput := make([][]float64, d.Config.MaxLength)
		for i, tok := range seq {
			row := make([]float64, d.Tokenizer.VocabSize)
			if tok >= 0 && tok < d.Tokenizer.VocabSize {
				row[tok] = 1.0
			}
			batchInput[i] = row
		}
		output2D := d.Network.ForwardTransformer(batchInput)
		preds := output2D[0]

		// fill in any [MASK] after [SEP]
		for i := sepPos + 1; i < d.Config.MaxLength; i++ {
			if seq[i] == maskID {
				start := i * d.Tokenizer.VocabSize
				end := start + d.Tokenizer.VocabSize
				probs := paragon.Softmax(preds[start:end])
				// Just pick argmax or threshold
				best := 0
				bestProb := probs[0]
				for m := 1; m < len(probs); m++ {
					if probs[m] > bestProb {
						bestProb = probs[m]
						best = m
					}
				}
				seq[i] = best
			}
		}
		// Optional re-masking for multi-step generation:
		// if t > 0 { ... re-mask with some probability ... }
	}

	// Gather emoticon portion
	emoticonIDs := []int{}
	for i := sepPos + 1; i < d.Config.MaxLength; i++ {
		if seq[i] == padID {
			break
		}
		emoticonIDs = append(emoticonIDs, seq[i])
	}
	return decodeCharLevel(d.Tokenizer, emoticonIDs)
}

// -------------------------------------------------------
// main()
// -------------------------------------------------------
func main() {
	rand.Seed(time.Now().UnixNano())

	// 1) Build a custom char-level tokenizer with [PAD], [MASK], [SEP]
	tok := &paragon.CustomTokenizer{
		Vocab:         make(map[string]int),
		ReverseVocab:  make(map[int]string),
		SpecialTokens: make(map[int]bool),
	}
	specials := []string{"[PAD]", "[MASK]", "[SEP]"}
	for i, s := range specials {
		tok.Vocab[s] = i
		tok.ReverseVocab[i] = s
		tok.SpecialTokens[i] = true
	}
	nextID := len(specials)
	// Add ASCII
	for c := rune(' '); c <= '~'; c++ {
		ch := string(c)
		if _, exists := tok.Vocab[ch]; !exists {
			tok.Vocab[ch] = nextID
			tok.ReverseVocab[nextID] = ch
			nextID++
		}
	}
	// Add unique chars from your pairs
	for _, p := range pairs {
		for _, r := range p.Word + p.Emoticon {
			c := string(r)
			if _, ok := tok.Vocab[c]; !ok {
				tok.Vocab[c] = nextID
				tok.ReverseVocab[nextID] = c
				nextID++
			}
		}
	}
	tok.VocabSize = nextID

	// 2) Compute maxSeqLen
	maxSeqLen := 0
	for _, p := range pairs {
		wLen := len([]rune(p.Word))
		eLen := len([]rune(p.Emoticon))
		seqLen := wLen + 1 + eLen
		if seqLen > maxSeqLen {
			maxSeqLen = seqLen
		}
	}

	// 3) Create config
	tConfig := paragon.TransformerConfig{
		DModel:      32,
		NHeads:      2,
		NLayers:     2,
		FeedForward: 32,
		VocabSize:   tok.VocabSize,
		MaxLength:   maxSeqLen,
		Activation:  "relu",
	}
	dConfig := paragon.DiffusionConfig{
		NumTimesteps:      5,
		MaxLength:         maxSeqLen,
		LearningRate:      0.01,
		Epochs:            1000, // reduce epochs for demo
		Temperature:       0.8,
		TopK:              1,
		MaskScheduleStart: 0.1,
		MaskScheduleEnd:   0.9,
	}

	// 4) Build network + model
	network := paragon.NewTransformerEncoder(tConfig)
	model := paragon.NewDiffusionModel(network, dConfig, []string{})
	model.Tokenizer = tok

	// 5) Prepare training samples
	sepID := tok.Vocab["[SEP]"]
	padID := tok.Vocab["[PAD]"]
	data := make([][]int, len(pairs))
	sepPositions := make([]int, len(pairs))
	for i, p := range pairs {
		wIDs := encodeCharLevel(tok, p.Word)
		eIDs := encodeCharLevel(tok, p.Emoticon)
		seq := append(wIDs, sepID)
		sepPos := len(wIDs)
		seq = append(seq, eIDs...)
		if len(seq) < maxSeqLen {
			padNeeded := maxSeqLen - len(seq)
			padding := make([]int, padNeeded)
			for j := range padding {
				padding[j] = padID
			}
			seq = append(seq, padding...)
		}
		data[i] = seq
		sepPositions[i] = sepPos
	}

	// 6) Train or load
	modelFile := "emoticon_model.gob"
	if _, err := os.Stat(modelFile); os.IsNotExist(err) {
		fmt.Println("No model file found; training with partial-masking after [SEP] ...")
		trainBetterDiffusionWithSepBatch(model, data, sepPositions)
		fmt.Println("Training complete. (Not saving for this demo.)")
	} else {
		fmt.Println("Model file found. For demo, we will just re-train anyway.")
		if err := model.Network.LoadFromGob(modelFile); err != nil {
			panic(fmt.Errorf("failed to load model from gob: %v", err))
		}
		trainBetterDiffusionWithSepBatch(model, data, sepPositions)
	}

	// 7) Generate final test
	fmt.Println("\nFinal test emoticons:")
	testWords := []string{"happy", "sad", "excited", "unknown"}
	for _, w := range testWords {
		gen := generateEmoticon(model, w)
		fmt.Printf("  Input: %s => %s\n", w, gen)
	}
}
